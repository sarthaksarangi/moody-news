# -*- coding: utf-8 -*-
"""SDP_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rDWqkxdEB9RRVDZ3IlzF2_8hWc7TcCpF
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score,confusion_matrix

df_test1='/content/drive/MyDrive/SDPProject/Twitter_Data.csv'
df=pd.read_csv(df_test1)

df=df[:10000]

df.sample(5)

df.shape

df

df['category'].value_counts()

df.isnull().sum()

df=df.dropna()

df.isnull().sum()

df.duplicated().sum()

df.drop_duplicates()

df.duplicated().sum()

sw_list=stopwords.words('english')
df['news'] = df['news'].apply(lambda x: [item for item in x.split() if item not in sw_list]).apply(lambda x:" ".join(x))

X=df.iloc[:,0:1]
Y=df['category']

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=35)

X_train.shape

X_train

X_test.shape

#Bag of Words
cv=CountVectorizer()

X_train_bow = cv.fit_transform(X_train['news'].values.astype('U')).toarray()
import joblib
joblib.dump(cv, "vectorizer.pkl")
X_test_bow=cv.transform(X_test['news']).toarray()

X_train_bow.shape

model=RandomForestClassifier()
model.fit(X_train_bow, Y_train)

Y_pred=model.predict(X_test_bow)
accuracy_score(Y_test, Y_pred)*100

import pickle

with open('model.pkl','wb') as file:
  pickle.dump(model, file)